{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['readMe', 'CLEAN DATA', 'GUIDESTAR MATCHING DATA', 'fb_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimeebarciauskas/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:13: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "execfile('load_data.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting terms for doc: 0\n",
      "counting terms for doc: 25\n",
      "counting terms for doc: 50\n",
      "counting terms for doc: 75\n",
      "counting terms for doc: 100\n",
      "counting terms for doc: 125\n",
      "counting terms for doc: 150\n",
      "counting terms for doc: 175\n",
      "counting terms for doc: 200\n",
      "counting terms for doc: 225\n",
      "counting terms for doc: 250\n",
      "counting terms for doc: 275\n",
      "counting terms for doc: 300\n",
      "counting terms for doc: 325\n",
      "counting terms for doc: 350\n",
      "counting terms for doc: 375\n",
      "counting terms for doc: 400\n",
      "counting terms for doc: 425\n",
      "counting terms for doc: 450\n",
      "counting terms for doc: 475\n",
      "counting terms for doc: 500\n",
      "counting terms for doc: 525\n",
      "counting terms for doc: 550\n",
      "counting terms for doc: 575\n",
      "counting terms for doc: 600\n",
      "counting terms for doc: 625\n",
      "counting terms for doc: 650\n",
      "counting terms for doc: 675\n",
      "counting terms for doc: 700\n",
      "counting terms for doc: 725\n",
      "counting terms for doc: 750\n",
      "counting terms for doc: 775\n",
      "counting terms for doc: 800\n",
      "Sanity checks:\n",
      "\tTime to build corpus: 5.84532189369\n",
      "\tTerms in first document: [u'give' u'stori' u'www' u'org' u'nfor' u'mani' u'year' u'went' u'life'\n",
      " u'truli' u'see' u'world' u'it' u'problem' u'knew' u'peopl' u'live'\n",
      " u'poverti' u'howev' u'wa' u'easi' u'thought' u'head' u'distract' u'daili'\n",
      " u'routin' u'coupl' u'year' u'ago' u'god' u'remov' u'blinder' u'eye'\n",
      " u'allow' u'truli' u'bless' u'famili' u'mani' u'famili' u'america'\n",
      " u'compar' u'part' u'world' u'process' u'wa' u'astonish' u'discov'\n",
      " u'billion' u'peopl' u'world' u'live' u'per' u'day' u'doe' u'someon'\n",
      " u'live' u'per' u'day' u'mani' u'america' u'will' u'pay' u'cup' u'coffe'\n",
      " u'nafter' u'god' u'began' u'reveal' u'thi' u'husband' u'felt' u'call'\n",
      " u'someth' u'help' u'sit' u'anymor' u'pretend' u'didn\\xe2' u'know' u'other'\n",
      " u'live' u'dire' u'circumst' u'truli' u'want' u'someth' u'give' u'husband'\n",
      " u'led' u'organ' u'call' u'help' u'orphan' u'underprivileg' u'children'\n",
      " u'south' u'africa' u'drawn' u'thi' u'organ' u'foremost' u'becaus'\n",
      " u'organization\\xe2' u'name' u'drawn' u'matthew' u'\\u0153truli' u'tell'\n",
      " u'whatev' u'brother' u'sister' u'mine' u'hear' u'stori' u'mani'\n",
      " u'children' u'serv' u'partner' u'commun' u'help' u'fix' u'problem'\n",
      " u'sustain' u'solut' u'felt' u'compel' u'join' u'effort' u'someth' u'help'\n",
      " u'rais' u'money' u'thi' u'wonder' u'organ' u'nbe' u'dancer' u'year'\n",
      " u'much' u'passion' u'love' u'danc' u'god' u'open' u'door' u'danc'\n",
      " u'ministri' u'coupl' u'year' u'ago' u'prayer' u'decid' u'danc' u'workshop'\n",
      " u'summer' u'help' u'benefit' u'wa' u'bless' u'involv' u'danc' u'time'\n",
      " u'amaz' u'opportun' u'use' u'time' u'talent' u'passion' u'help'\n",
      " u'children' u'south' u'africa' u'desper' u'need' u'help' u'ndure'\n",
      " u'workshop' u'wa' u'abl' u'talk' u'children' u'serv' u'children' u'live'\n",
      " u'small' u'hut' u'floor' u'walk' u'everi' u'day' u'distanc' u'collect'\n",
      " u'water' u'famili' u'children' u'ask' u'wa' u'make' u'stori' u'sinc' u'wa'\n",
      " u'hard' u'imagin' u'life' u'children' u'south' u'africa' u'know' u'wa'\n",
      " u'veri' u'heartwarm' u'children' u'come' u'workshop' u'empti' u'piggi'\n",
      " u'bank' u'give' u'hear' u'stori' u'children' u'serv' u'addit' u'money'\n",
      " u'abl' u'rais' u'dure' u'workshop' u'know' u'workshop' u'great' u'impact'\n",
      " u'children\\xe2' u'heart' u'mine' u'feel' u'veri' u'bless' u'opportun'\n",
      " u'give' u'help' u'children' u'south' u'africa' u'learn' u'thi' u'give'\n",
      " u'experi' u'god' u'call' u'someth' u'process' u'hand' u'feet' u'jesu'\n",
      " u'can' u'amaz' u'impact' u'thi' u'world' u'mind' u'go' u'within' u'commit'\n",
      " u'will' u'can' u'help' u'believ' u'give' u'time' u'talent' u'treasur'\n",
      " u'can' u'part' u'someth' u'much' u'bigger' u'ourselv' u'join' u'forc'\n",
      " u'god' u'someth' u'help' u'other' u'think' u'will' u'amaz' u'onli' u'will'\n",
      " u'other\\xe2' u'live' u'help' u'impact' u'becaus' u'life' u'will' u'chang'\n",
      " u'heart' u'transform' u'hi' u'know' u'mine' u'ha' u'beauti' u'thing']\n",
      "\tTotal words in corpus: 151574\n",
      "\tNumber docs in corpus: 823\n",
      "\tNumber of unique words in corpus: 10828\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "execfile('nlp_code/corpus.py')\n",
    "execfile('nlp_code/document.py')\n",
    "\n",
    "t0 = time.time()\n",
    "corpus = Corpus(documents, 'nlp_code/stopwords.txt', 2)\n",
    "t1 = time.time()\n",
    "\n",
    "corpus.generate_document_term_matrix()\n",
    "termlist = list(corpus.token_set)\n",
    "print 'Sanity checks:'\n",
    "print '\\tTime to build corpus: ' + str(t1 - t0)\n",
    "print '\\tTerms in first document: ' + str(corpus.docs[0].tokens)\n",
    "print '\\tTotal words in corpus: ' + str(corpus.ntotal_tokens)\n",
    "print '\\tNumber docs in corpus: ' + str(corpus.N)\n",
    "print '\\tNumber of unique words in corpus: ' + str(len(corpus.token_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent running LDA: 21.2002379894\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix = np.array(corpus.document_term_matrix, dtype = 'int')\n",
    "\n",
    "model = lda.LDA(n_topics=10, n_iter=1000, random_state=1)\n",
    "time0 = time.time()\n",
    "model.fit(doc_term_matrix)\n",
    "time1 = time.time()\n",
    "\n",
    "print 'Time spent running LDA: {0}'.format(time1-time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10828\n",
      "Topic 0: give thi help peopl year ha can time\n",
      "Topic 1: commun nicu support danc free perform wa provid\n",
      "Topic 2: run girl world pacer mile friend smile will\n",
      "Topic 3: project will book health www work life local\n",
      "Topic 4: children food child famili home love hous provid\n",
      "Topic 5: cancer famili wa hope foundat diseas thi brain\n",
      "Topic 6: wa year kid volunt love work veri time\n",
      "Topic 7: school student educ children program colleg girl commun\n",
      "Topic 8: wa hi time day life told month thi\n",
      "Topic 9: dog anim rescu cat adopt care wildlif home\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "vocab = np.array(list(corpus.token_set))\n",
    "print len(topic_word[0])\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    top_word_idcs = list(np.argsort(topic_dist))\n",
    "    top_word_idcs.reverse()\n",
    "    topic_words = vocab[top_word_idcs[0:n_top_words]]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
